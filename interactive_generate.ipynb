{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9daa013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aec1a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from accelerate import PartialState\n",
    "from accelerate.utils import gather_object\n",
    "import argparse\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, TextStreamer, BitsAndBytesConfig\n",
    "from utils.utils import *\n",
    "from utils.metrics import *\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_path\", type=str)\n",
    "    parser.add_argument(\"--test_data\", type=str)\n",
    "    parser.add_argument(\"--output_dir\", type=str)\n",
    "    parser.add_argument(\"--max_new_tokens\", type=int)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
    "    parser.add_argument('--use_flash_attention_2', action='store_true')\n",
    "    parser.add_argument('--add_bos_token', action='store_true')\n",
    "    args,_ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_tokenizer_and_model(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)\n",
    "    if args.use_flash_attention_2:\n",
    "        model = AutoModelForCausalLM.from_pretrained(args.model_path, device_map={\"\": accelerator.process_index}, attn_implementation=\"flash_attention_2\", trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(args.model_path, trust_remote_code=True)\n",
    "    tokenizer.padding_side='left'\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer, model\n",
    "\n",
    "# QA\n",
    "def get_prompt(tokenizer, title, context, question, tokenize=False, add_bos_token=False):\n",
    "    \n",
    "    document = title+' '+context\n",
    "    prompt = f\"질문:{question}\\n지문:{document}\\n답변:\"\n",
    "    if add_bos_token:\n",
    "        prompt = tokenizer.bos_token + prompt\n",
    "    return prompt\n",
    "# def get_prompt(tokenizer, premise, hypothesis, tokenize=False, add_bos_token=False):\n",
    "#     prompt = f\"전제: {premise}\\n가설: {hypothesis}\\n주어진 가설과 전제는 어떠한 관계인가\\n{OPTIONS}\"#prompt = f\"질문:{question}\\n지문:{document}\\n답변:\"\n",
    "#     if add_bos_token:\n",
    "#         prompt = tokenizer.bos_token + prompt\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29d67f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcdb3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "args = get_args()\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eda1ab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t     midm_10b_plm_70k\n",
      "domain_refine_flatten\t     midm_v3_normal_adjusted\n",
      "domain_refine_merge_version  midm_v3_only_josa_adjusted\n",
      "gpt4\t\t\t     nli\n",
      "heuristic_filtering\t     remove_duplicate\n",
      "llama3.1\n"
     ]
    }
   ],
   "source": [
    "! ls ../kt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "625bedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path = f'../kt_output/midm_v3_normal_adjusted/qa/model_2'\n",
    "args.test_data = '/home/work/g-earth-22/hoyoun/downstream/data/KorQuad_dev.jsonl'\n",
    "# args.test_data = '/home/work/user/ocw/SFT/data/klue_nli_dev.jsonl'\n",
    "args.use_flash_attention_2=True\n",
    "args.max_new_tokens=64\n",
    "args.add_bos_token = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19bbaff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5774it [00:00, 87395.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer, model\n",
    "tokenizer, model  = get_tokenizer_and_model(args)\n",
    "test_data = load_jsonl(args.test_data)\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70271af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa3deeb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "1989년 2월 15일\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/50 [00:00<00:15,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n",
      "임수경\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/50 [00:00<00:09,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "1989년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 3/50 [00:00<00:08,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "경희대학교\n",
      "246\n",
      "서울지방경찰청 공안분실\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 5/50 [00:00<00:06,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "임종석\n",
      "259\n",
      "폭력행위등처벌에관한법률위반\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 7/50 [00:01<00:06,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "허영\n",
      "207\n",
      "10차 개헌안\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 9/50 [00:01<00:05,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "제89조\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 10/50 [00:01<00:05,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "허영\n",
      "190\n",
      "부참모 총장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 12/50 [00:01<00:04,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "국무장관\n",
      "193\n",
      "로널드 레이건\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 14/50 [00:02<00:04,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "리처드 닉슨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 15/50 [00:02<00:04,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "부참모 총장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 16/50 [00:02<00:04,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "2세\n",
      "198\n",
      "국무장관\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 18/50 [00:02<00:03,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "경고:현실주의, 레이건과 외교 정책\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 19/50 [00:02<00:04,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "퍼트리샤 앤토이넷 폭스\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 20/50 [00:03<00:05,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "1944년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [00:03<00:04,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "3명\n",
      "192\n",
      "노터데임 대학교\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% 23/50 [00:03<00:04,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "퍼트리샤 앤토이넷 폭스\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% 24/50 [00:03<00:04,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "노터데임\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 25/50 [00:03<00:04,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n",
      "기갑 훈련소\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% 26/50 [00:04<00:04,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "퍼트리샤 앤토이넷 폭스\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 27/50 [00:04<00:04,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "1979년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 28/50 [00:04<00:03,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "닉슨\n",
      "184\n",
      "5년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 30/50 [00:04<00:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "1979년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% 31/50 [00:04<00:02,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "미국 유럽 연합군\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 32/50 [00:04<00:02,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "1979년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% 33/50 [00:05<00:02,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "미국 기술 주식 회사\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68% 34/50 [00:05<00:02,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "외교 정책의 아마추어\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 35/50 [00:05<00:02,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "1988년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72% 36/50 [00:05<00:01,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "Worldwide Associates Inc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% 37/50 [00:05<00:01,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "1988년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% 38/50 [00:05<00:01,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "외교 정책의 아마추어\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78% 39/50 [00:05<00:01,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "1988년\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 40/50 [00:05<00:01,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "노아\n",
      "313\n",
      "창세기\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84% 42/50 [00:06<00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "고페르나무\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% 43/50 [00:06<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "하나님의 명령\n",
      "312\n",
      "3층\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 45/50 [00:06<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "아스팔트와 비슷한 성분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% 46/50 [00:06<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "약 135m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94% 47/50 [00:06<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "8층\n",
      "310\n",
      "고페르나무\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% 49/50 [00:07<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "기독교\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 50/50 [00:07<00:00,  7.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in test_data:\n",
    "    prompt = get_prompt(tokenizer, i['title'],i['context'], i['question'], tokenize=False, add_bos_token=args.add_bos_token)\n",
    "#     prompt = get_prompt(tokenizer, i['premise'], i['hypothesis'], tokenize=False, add_bos_token=args.add_bos_token)\n",
    "    i['input']=prompt\n",
    "\n",
    "terminators = [tokenizer.eos_token_id]\n",
    "streamer = None\n",
    "if accelerator.is_main_process and batch_size == 1:\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True) \n",
    "completions_per_process = []\n",
    "n_samples = 50\n",
    "for d in tqdm(test_data[:n_samples], disable=accelerator.is_main_process != True):\n",
    "    batch = tokenizer(d['input'], add_special_tokens=False, return_tensors='pt')\n",
    "    batch = batch.to(accelerator.device)\n",
    "    length = batch['input_ids'].size(1)\n",
    "    print(length)\n",
    "    # just greedy\n",
    "    outputs = model.generate(input_ids = batch['input_ids'], streamer=streamer, eos_token_id=terminators, pad_token_id = tokenizer.eos_token_id, num_beams=1, max_new_tokens=args.max_new_tokens, do_sample=False)\n",
    "    outputs = outputs[:,length:].contiguous()\n",
    "    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    completions_per_process.extend(generated_text)\n",
    "#     print(LABEL2STR[d['label']])\n",
    "#     print('=========================================')\n",
    "#     input()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0348e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = copy.deepcopy(completions_per_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ee5a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "josa = copy.deepcopy(completions_per_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca76195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f3e4b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.846952380952381, 'em': 0.76}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(normal,[[i['answer']] for i in test_data[:n_samples]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4caaf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.846952380952381, 'em': 0.76}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(josa,[[i['answer']] for i in test_data[:n_samples]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ac770989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5774it [00:00, 47683.38it/s]\n"
     ]
    }
   ],
   "source": [
    "normal = load_jsonl('/home/work/user/ocw/kt_output/midm_v3_normal_adjusted/qa/model_2/attached.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "483bcfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5774it [00:00, 50908.23it/s]\n"
     ]
    }
   ],
   "source": [
    "josa = load_jsonl('/home/work/user/ocw/kt_output/midm_v3_only_josa_adjusted/qa/model_2/attached.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a15b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6395260312561997, 'em': 0.584170419120194}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores([i['predict'] for i in josa],[[i['answer']] for i in normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac897509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.5314202692969565, 'em': 0.4823346033945272}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores([i['predict'] for i in normal],[[i['answer']] for i in normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "99979062",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "# both_wrongs = []\n",
    "just_normal_wrongs = []\n",
    "for i,j in zip(normal, josa):\n",
    "    if i['answer']!=i['predict'] and j['answer']==j['predict']:\n",
    "        \n",
    "#     if i['predict']!=j['predict']:\n",
    "        normal_predict = i['predict']\n",
    "        josa_predict = j['predict']\n",
    "        tmp = copy.deepcopy(i)\n",
    "        tmp['normal_predict']=normal_predict\n",
    "        tmp['josa_predict']=josa_predict\n",
    "#         differences.append(copy.deepcopy(tmp))\n",
    "#         both_wrongs.append(tmp)\n",
    "        just_normal_wrongs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f083025",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_wrong = []\n",
    "josa_wrong = []\n",
    "for i in differences:\n",
    "#     print('document')\n",
    "#     print(i['title']+' '+i['context'])\n",
    "#     print('question')\n",
    "#     print(i['question'])\n",
    "    if i['normal_predict']!=i['answer']:\n",
    "        normal_wrong.append(i)\n",
    "        # normal이 틀린 경우\n",
    "#         print('normal_wrong')\n",
    "#         print(f'normal ----- %s'%i['normal_predict'])\n",
    "#         print(f'josa ----- %s'%i['josa_predict'])\n",
    "#         print(f'answer ----- %s'%i['answer'])\n",
    "    elif i['josa_predict']!=i['answer']:\n",
    "        josa_wrong.append(i)\n",
    "#         print('normal_wrong')\n",
    "#         print(f'normal ----- %s'%i['normal_predict'])\n",
    "#         print(f'josa ----- %s'%i['josa_predict'])\n",
    "#         print(f'answer ----- %s'%i['answer'])\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6042bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = random.sample(just_normal_wrongs, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bd274f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b333a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "우루과이_축구_국가대표팀 FIFA에서는 월드컵 우승 팀에게 유니폼에 '우승'을 상징하는 '별'을 달 것을 권장하고 있다. 우루과이는 2회 월드컵 우승(1930, 1950)에 더해, 월드컵 창립 이전에 실시된 올림픽경기대회 축구 종목에서의 금메달 2회 획득(1924, 1928)을 근거로, 총 별 4개를 유니폼에 새겨넣고 있다. 1920년대의 올림픽 우승을 기리는 이유는 당시는 월드컵 대회가 출범하기 이전이었으며, 유럽팀이 최강이라는 인식이 자리 잡고 있던 시기에 올림픽 축구를 남미국가가 제패함으로써, 아마추어 선수로 출전자격이 제한된 올림픽 무대와는 별도로 진정한 세계 최강팀을 가리는 대회를 만들자는 공감대가 형성되었으며, 그로인해 1930년 제1회 우루과이 월드컵이 개최되는 계기가 되었기 때문이다.\n",
      "question\n",
      "FIFA월드컵 우승팀이 유니폼에 다는 것은?\n",
      "normal_wrong\n",
      "normal ----- 4개\n",
      "josa ----- 별\n",
      "answer ----- 별\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 더 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "이회창 1997년 대선 당시 한나라당 이회창 후보는 지역감정 문제에 대한 공방에 \"영남출신 대의원들이 비영남인 저를 뽑아준 이 정당이 지역주의입니까? 90 몇 %를 차지하고 전혀 다른 지역 출신의 개입을 허용하지 않는 정당이 지역주의 정당입니까?\"라는 발언으로 지역감정을 유발한다. 또 12월 16일 서울에서 열린 선거 유세에서는 \"여러분이 김대중 후보를 당선시켜서 이 나라를 혼란에 빠뜨리고 불안정하게 하는 것이 소망이라고 생각하신다면은 그러면 이인제나 김대중 후보에게 표를 던지십시요.\"라는 위험수위를 넘는 발언으로 논란을 빚었다. 다음날인 12월 17일 부산에서 열린 선거 유세에서는 \"이분(이인제)에게 던지는 표는 이것은 바로 아무런 효과도 내지 못하는 죽은 표가 될 뿐 아니라 바로 우리가 걱정하는 김대중 총재를 위한 표가 될 것입니다\"라는 발언으로 반호남정서를 유발하는 발언을 한다.\n",
      "question\n",
      "1997년 당시 이회창의 발언으로 무엇을 유발하였나?\n",
      "normal_wrong\n",
      "normal ----- 김대중\n",
      "josa ----- 지역감정\n",
      "answer ----- 지역감정\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "대한민국_아파트의_역사 1941년과 1944년에 부산토지공사가 지은 청풍장-소화장아파트는 부산광역시에 지어진 최초의 4층 짜리 아파트이다. 초기에는 아파트와 부산광역시청 겸용으로 지었으나 이후 건물 전체가 아파트로 사용되었으며 부산 최고의 공동주택이었는데 1980년대까지 외관은 아주 노후해서 놀라고, 안에 들어가면 넓어서 또 놀라고, 그리고 집주인이 부자라서 놀라서 세 번 놀란다는 말까지 생길 정도로 당시 최고급 아파트라는 것을 인증했다. 그러나 1996년 안전진단에서 D등급을 판정받았으나 부지가 작아 재개발이 시행되지 않고 있다. 그러다가 문화재청이 등록문화재로 지정하려고 부산광역시에 알리면서 관심이 커졌으며 문화유산으로 지정은 되지 않았지만 부산광역시의 근대문화유산으로 지정, 보존을 추진하고 있다.\n",
      "question\n",
      "청풍장-소화장아파트는 부산광역시에서 등록문화재 대신 무엇으로 지정되었는가?\n",
      "normal_wrong\n",
      "normal ----- 문화재\n",
      "josa ----- 근대문화유산\n",
      "answer ----- 근대문화유산\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "뉘르부르크링 노르트슐라이페의 랩타임을 차량의 성능과 드라이버의 실력을 평가하는 좋은 척도가 된다. 그래서 랩타임 기록을 깨기위한 수많은 노력이 있었고, 그 실력을 인정받은 드라이버는 링마이스터 칭호를 받을 수 있었다. 지금까지 트랙에 변화가 여러번 있었기 때문에, 1920년대 부터 통용되는 공식 순위는 없으나, 트랙 개량에 따라 랩 타임 순위가 나뉘어 있다. 지금까지 가장 빠른 기록은 6분 11초 13로, 1983년에 뉘르부르크링 1000km에서 스테판 벨로프 선수가 포르쉐 956으로 기록하였다. 현재는 노르트슐라이페에서 메이저 경기가 열리지 않기 때문에, 스테판 벨로프 선수의 기록보다 빠른 기록은 없다. 레이스카를 제외한 차량 중 가장 빠른 기록은 포르쉐 911 GT2 RS 가 세운 6분 47초이다.\n",
      "question\n",
      "스테판 벨로프 선수가 가장 빠른 랩타임을 기록한 당시 탔던 차량은?\n",
      "normal_wrong\n",
      "normal ----- 포르쉐 911 GT2 RS\n",
      "josa ----- 포르쉐 956\n",
      "answer ----- 포르쉐 956\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "금강산 현대그룹 창업자 정주영이 1989년 방북하여 금강산 관광개발 의정서를 체결한 9년 뒤인 1998년 11월 18일에 금강호가 첫 출항함으로써 본격적인 금강산 관광이 시작되었다. 2001년 1월 6일부터 3년 동안 한국 최초의 호텔식 테마 여객선 설봉호를 이용하여 해로 관광이 가능해졌다. 금강산 지역은 2002년 11월 23일에 금강산관광지구라는 특별행정구역으로 명명되었다. 2003년 2월 14일 DMZ를 통과하는 역사적인 육로 관광이 시범 운영된 뒤로 육로 관광이 계속 유지되고 있으며, 이 육로 관광은 버스를 이용하여 금강산으로 갈 수 있도록 되어 있다. 매년 관광객 수 증가에 큰 영향을 미치고 있다. 도중에 몇 차례 중단된 적이 있었는데, 정몽헌의 자살, 사스 사태, 민간인 민영미 억류 사건이 일어났을 때이다. 이중 억류 사건은, 관광 세칙과 신변안전보장 합의서를 체결한 후 일단락되었다. 2008년 3월부터는 자가용을 이용한 승용차관광도 할 수 있게 되었다. 현대아산 측은 2005년 6월에 금강산 관광객이 100만 명을 돌파했다고 발표 했으며, 2008년 말 기준으로 통산 관광객 수는 195만 명에 달한다.\n",
      "question\n",
      "DMZ를 통과하는 금강산 육로관광이 시작된 해는?\n",
      "normal_wrong\n",
      "normal ----- 2008년\n",
      "josa ----- 2003년\n",
      "answer ----- 2003년\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "이회창 8월 26일 이회창은 심대평 대표에 대한 총리 기용설과 관련, \"앞으로 이에 관한 이야기는 일체 나오지 않았으면 한다\"고 밝혔다. 이 총재는 이날 국회에서 열린 당5역회의에서 \"심 대표의 총리 기용 여부와 관련해 마치 당에 내분이 일어나는 것처럼 비쳐지고 있는 것은 매우 유감스러운 일\"이라고 말했다. 이 발언은 정치연대의 틀 없이 선진당 소속 의원이 내각에 참여할 수 없다는 기존 원칙을 강조한 것으로 보인다는 평가가 있다. 그는 또한 \"당직자들이 개인 의견을 말하는 것은 당에 전혀 도움이 되지 않는다\"며 \"외부의 추측과 풍문 때문에 쓸데없이 우리당 스스로 내분과 같은 양상으로 비쳐지는 것은 경계해야 한다\"고 지적했다. 이후 8월 30일 자유선진당 심대평 대표가 이회창 총재의 독선적 당 운영에 불만을 제기하면서 탈당하였다. 심 대표의 탈당으로 자유선진당과 창조한국당이 함께 구성한 교섭단체(선진과 창조의 모임)가 붕괴되었다. 탈당에 대해 이회창은 \"어려움을 함께 하면서 여기까지 왔는데 이렇게 돼서 안타깝고 가슴 아프다\" 고 말했다고 박선영 대변인이 전했다. 9월 3일 그가 자유선진당 세비기금 전달차 들른 대전 서구 둔산동 오페라웨딩에서 가진 기자회견에서 \"자유선진당이 원내교섭단체 지위를 잃었다고 해서 생명줄이 끊어진 것은 아니다\"며 \"우리는 17석을 갖고 최대한 맡은 일을 해낼 것이고, 원내교섭단체 구성도 모색할 것\"이라고 밝혔다. 또 심대평 대표의 국무총리 입각 반대 배경에 대해 \"심 전 대표가 국무총리에 입각하는 것은 현 정권의 한복판에 들어가는 것인데 과연 그렇게 했을 때 선진당이 그동안 반대해 온 '4대강 살리기 사업' 등을 강하게 비판하고 반대할 수 있겠느냐\"며 반문했다. 그는 그러면서 \"선진당이 미디어법 등 개별사안에 대해 다른 정당과 정책적으로 공조하는 것과 총리 입각 등 큰 틀에서 공조하는 것은 차원이 전혀 다르다\"고 강조했다. 자유선진당이 이회창 총재한테 너무 많은 권한이 집중돼 있다는 지적이 있는데 일선에 후퇴할 생각이 없느냐는 질문에는 \"총재 자리에서 사퇴하라는 얘기는 여기와서 처음 들어봤다\"고 일축한 뒤 \"나는 그동안 모든 일을 철저하게 토론을 통해 결정했다. 내가 일방적으로 모든 일을 결정해 왔다는 것에 대해 아무도 동의하지 않을 것\"이라고 말했다. 그는 심 전 대표에 대한 복당 요구가 '립서비스'에 불과하다는 지적에 대해 \"결코 립서비스가 아니다. 직접 찾아뵙고 싶었지만 잘 안됐고, 전화연락도 안된다는 얘기를 들었다\"며 \"진심으로 돌아오기를 바란다\"고 말했다. 이밖에 이 총재는 무소속 이인제 의원과 염홍철 전 대전시장의 영입 여부에 대해 \"이 자리에서 특정인을 언급하는 것은 적절치 않은 만큼 언급하지 않겠다\"며 말을 아꼈다.\n",
      "question\n",
      "8월30일 이회창 총재의 독선적 당 운영에 불만을 제기하며 탈당한 자유선진당 대표는?\n",
      "normal_wrong\n",
      "normal ----- 이회창\n",
      "josa ----- 심대평\n",
      "answer ----- 심대평\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "중화인민공화국의_법 중재(중국에서는 이를 公斷이라고도 한다)에 대하여 중화인민공화국 성립이전에는 중국에 중재법이나 독립적인 중재기구가 존재하지 않았다. 중화인민공화국이 성립한 후 중국정부는 대외 무역 촉진에 힘쓰는 한편 대외무역에 있어서 중재의 효용을 인식하게 되었고, 현재는 “중재법”이 제정되어 있다. 동법은 가족관계에 관한 민사분쟁, 행정쟁송, 노동분쟁 (별도로 중재제도를 정하고 있다.), 농업집단경제조직 내부의 농업 도급 계약 분쟁 (별도의 중재제도를 정하고 있다.)에 대하여는 적용되지 않는다. 동법의 적용이 있는 민사분쟁에 대하여는 당사자는 중재합의를 기반으로, 일반 행정구 인민정부 소재시의 인민정부에 설치되어 있는 중재위원회에 중재의 신청을 할 수 있다.(중재합의가 있는데도 인민정부에 제소하여도 수리되지 아니한다.) 중재는 중재위원회가 사건마다 임명하는 중재인이 행한다. 중재 재정은 1심으로 종국 판단을 하여, 절차의 하자를 이유로 인민법원에 취소를 구하는 것이 가능한 이외에는, 불복을 신청할 수 없다. 중국 민사소송법 제231조는 소송의 해결까지 사이에, 외국인 당사자에 대하여 인민법원에 의한 출국정지처분을 인정하고 있다. 근래에 일본기업에 대해 종업원이나 거래선이 소송을 제기하여, 기업의 책임자 등이 출국정지처분을 받는 예가 급증하여, 문제가 되고 있다.\n",
      "question\n",
      "중국에서 중재인을 임명하는 곳은 어디인가?\n",
      "normal_wrong\n",
      "normal ----- 인민법원\n",
      "josa ----- 중재위원회\n",
      "answer ----- 중재위원회\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "바이오쇼크 게임은 1960년 랩쳐가 붕괴된 직후 잭(게임의 주인공)이 탄 비행기가 대서양을 지나는 중 불시착하는 것으로 시작한다. 추락 후에, 잭은 이 참사에서 살아남은 사람은 자신밖에 없음을 알게 되고, 가까운 곳에 등대가 설치된 섬을 발견하고 수영해 간다. 그 곳에는 수중 도시인 랩쳐로 들어가기 위한 구형 잠수기가 설치되어 있었다. 아일랜드 사람이라고 밝힌 아틀라스는 잠수함에 있는 무전기로 잭을 안전하게 인도한다. 그러는 동안 라이언은 잭을 육지 국가에서 온 요원으로 믿고 랩쳐의 자동화 시스템과 그의 페로몬으로 조정하는 스플라이서를 이용해 공격하게 한다. 아틀라스는 잭에게 살 수 있는 유일한 방법은 플라스미드로부터 받은 능력을 이용하고, ADAM을 추출하기 위해 반드시 리틀 시스터를 죽여야 한다고 말한다. 아틀라스의 말을 우연히 들은 테넌바움 박사는 잭에게 리틀 시스터를 살려야 한다고 강하게 주장하며, 각각의 리틀 시스터가 깊숙히 갖고 있던 바다 달팽이를 바꿔 플라스미드로 줄 거라고 말한다. 아틀라스는 그의 아내와 자식들이 잠수함에 숨어 있다고 하며 잭을 잠수함으로 인도한다. 잭과 아틀라스가 잠수함이 있는 만(灣)에 도착하는데 그때 라이언이 그것을 파괴시킨다. 분노한 아틀라스는 잭에게 라이언을 죽여달라고 요청한다.\n",
      "question\n",
      "잠수함에 있는 무전기로 잭을 안전하게 인도한 아일랜드 사람의 이름은 무엇인가?\n",
      "normal_wrong\n",
      "normal ----- 테넌바움\n",
      "josa ----- 아틀라스\n",
      "answer ----- 아틀라스\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 원하는 것을 못찾음\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "대한민국_아파트의_역사 개포주공아파트는 1981년 현대건설이 지은 주공아파트이다. 또한 전두환 정권이 도입하였던 택지개발촉진법의 첫 사례이기도 하다. 1980년대 당시 강남개발로 인해 사람들이 강남에 몰리자 정부는 주택난을 해소하기 위하여 주공아파트를 여러 곳에 짓기로 결심한다. 이곳 중 잘 알려진 곳이 개포주공아파트와 개포시영아파트이다. 개포주공아파트는 1단지에서 7단지까지 지어졌으며 현재 재개발에 들어갈 예정이다. 서울시는 이전부터 재개발계획이 있었으나 여러 문제로 인해 미루어지다 최근 들어서 조합이 설립되는 등 재개발시행에 본격적으로 들어갔다. 하지만 서울시의 층수제한에 많은 논란이 일면서 갈등이 있었으나 현재는 용적률 300%로 동의가 된 상태로 이제 최종허가와 보상만 하면 되는 실정이다.\n",
      "question\n",
      "개포주공아파트는 몇 단지로 이루어져 있나?\n",
      "normal_wrong\n",
      "normal ----- 개포주공아파트\n",
      "josa ----- 7단지\n",
      "answer ----- 7단지\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer ----- %s\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     elif i['josa_predict']!=i['answer']:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         josa_wrong.append(i)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# #         print('normal_wrong')\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# #         print(f'normal ----- %s'%i['normal_predict'])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# #         print(f'josa ----- %s'%i['josa_predict'])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# #         print(f'answer ----- %s'%i['answer'])\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for i in samples:\n",
    "    print('document')\n",
    "    print(i['title']+' '+i['context'])\n",
    "    print('question')\n",
    "    print(i['question'])\n",
    "    print('normal_wrong')\n",
    "    print(f'normal ----- %s'%i['normal_predict'])\n",
    "    print(f'josa ----- %s'%i['josa_predict'])\n",
    "    print(f'answer ----- %s'%i['answer'])\n",
    "#     elif i['josa_predict']!=i['answer']:\n",
    "#         josa_wrong.append(i)\n",
    "# #         print('normal_wrong')\n",
    "# #         print(f'normal ----- %s'%i['normal_predict'])\n",
    "# #         print(f'josa ----- %s'%i['josa_predict'])\n",
    "# #         print(f'answer ----- %s'%i['answer'])\n",
    "    i['memo']=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cdee87e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [539, 714, 31855, 7531, 271, 2039, 40676, 11852, 11964, 33], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('개포주공아파트는 몇 단지로 이루어져 있나?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "48f37027",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_josa = AutoTokenizer.from_pretrained('../kt_output/midm_v3_only_josa_adjusted/qa/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f1b27d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'개'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "75fbd71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [539, 714, 31855, 7531, 271, 2039, 40676, 11852, 11964, 33], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('개포주공아파트는 몇 단지로 이루어져 있나?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1eb93f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스테\n",
      "판\n",
      " 벨\n",
      "로프\n",
      " 선수가\n",
      " 가장\n",
      " 빠른\n",
      " 랩\n",
      "타임을\n",
      " 기록한\n",
      " 당시\n",
      " 탔\n",
      "던\n",
      " 차량은\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for i in tokenizer.encode('스테판 벨로프 선수가 가장 빠른 랩타임을 기록한 당시 탔던 차량은?'):\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0deae16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스테\n",
      "판\n",
      " 벨\n",
      "로프\n",
      " 선수\n",
      "가\n",
      " 가장\n",
      " 빠른\n",
      " 랩\n",
      "타임\n",
      "을\n",
      " 기록한\n",
      " 당시\n",
      " 탔\n",
      "던\n",
      " 차량\n",
      "은\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for i in tokenizer_josa.encode('스테판 벨로프 선수가 가장 빠른 랩타임을 기록한 당시 탔던 차량은?'):\n",
    "    print(tokenizer_josa.decode([i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e758ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict,Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "605f5d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'원하는 부분을 못찾음': 6, '맞음': 3, '맞음 (분석 필요)': 1})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([i['memo'] for i in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f88a6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2438"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7c4a842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(josa_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27ecf199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1989년 2월 15일'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences[0][1]['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d7380d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7373333333333334, 'em': 0.64}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(josa,[[i['answer']] for i in test_data[:n_samples]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
